{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String, Float, Date, text\n",
    "import pandas as pd\n",
    "#nima part\n",
    "df_dataset = pd.read_csv(\"/Users/Vengeance/Documents/GitHub/earthquake-analysis-japan/JAPAN_DATASET_cleaned.csv\")\n",
    "df_emsc = pd.read_csv(\"/Users/Vengeance/Documents/GitHub/earthquake-analysis-japan/JAPAN_EMSC_cleaned.csv\")\n",
    "df_geofon = pd.read_csv(\"/Users/Vengeance/Documents/GitHub/earthquake-analysis-japan/JAPAN_GEOFON_cleaned.csv\")\n",
    "df_usgs = pd.read_csv(\"/Users/Vengeance/Documents/GitHub/earthquake-analysis-japan/JAPAN_USGS_cleaned.csv\")\n",
    "\n",
    "def clean_df(df, source_name):\n",
    "    if 'place' in df.columns and 'region' in df.columns:\n",
    "        df = df.drop(columns=['place'])\n",
    "    if 'latitude' in df.columns and 'longitude' in df.columns:\n",
    "        df['coordination'] = df.apply(lambda x: f\"[{x.latitude}, {x.longitude}]\", axis=1)\n",
    "    rename_map = {}\n",
    "    if 'mag' in df.columns:\n",
    "        rename_map['mag'] = 'magnitude'\n",
    "    if 'place' in df.columns and 'region' not in df.columns:\n",
    "        rename_map['place'] = 'region'\n",
    "    df = df.rename(columns=rename_map)\n",
    "    df['source'] = source_name\n",
    "    # columns_needed = ['time', 'coordination', 'depth', 'magnitude', 'region', 'source']\n",
    "    # df = df[[c for c in columns_needed if c in df.columns]]\n",
    "    if 'time' in df.columns:\n",
    "        df['time'] = pd.to_datetime(df['time'], errors='coerce').dt.date\n",
    "    if 'depth' in df.columns:\n",
    "        df['depth'] = pd.to_numeric(df['depth'], errors='coerce')\n",
    "    if 'magnitude' in df.columns:\n",
    "        df['magnitude'] = pd.to_numeric(df['magnitude'], errors='coerce')\n",
    "    return df\n",
    "\n",
    "df_dataset = clean_df(df_dataset, \"Dataset\")\n",
    "df_emsc = clean_df(df_emsc, \"EMSC\")\n",
    "df_geofon = clean_df(df_geofon, \"GEOFON\")\n",
    "df_usgs = clean_df(df_usgs, \"USGS\")\n",
    "\n",
    "\n",
    "df_final = pd.concat([df_dataset, df_emsc, df_geofon, df_usgs], ignore_index=True)\n",
    "columns_needed = ['time', 'coordination', 'depth', 'magnitude', 'region', 'source']\n",
    "df_final = df_final[[c for c in columns_needed if c in df_final.columns]]\n",
    "\n",
    "df_final = df_final.dropna(subset=['time', 'magnitude', 'region'])\n",
    "df_final = df_final.drop_duplicates()\n",
    "\n",
    "engine = create_engine(\"mysql+pymysql://root:nimaaslrousta717@localhost:3306/earthquakes_db\")\n",
    "connection = engine.connect()\n",
    "metadata = MetaData()\n",
    "\n",
    "earthquakes = Table(\n",
    "    'Earthquakes',\n",
    "    metadata,\n",
    "    Column('id', Integer, primary_key=True),\n",
    "    Column('time', Date),\n",
    "    Column('coordination', String(50)),\n",
    "    Column('depth', Float),\n",
    "    Column('magnitude', Float),\n",
    "    Column('region', String(100)),\n",
    "    Column('source', String(50))\n",
    ")\n",
    "\n",
    "connection.execute(text(\"DROP TABLE IF EXISTS Earthquakes;\"))\n",
    "metadata.create_all(engine)\n",
    "\n",
    "df_final.to_sql(\n",
    "    name='Earthquakes',\n",
    "    con=engine,\n",
    "    if_exists='append',\n",
    "    index=False,\n",
    "    chunksize=1000\n",
    ")\n",
    "\n",
    "count = connection.execute(text(\"SELECT COUNT(*) FROM Earthquakes;\")).scalar()\n",
    "print(f\"Number of rows inserted: {count}\")\n",
    "#sepehr queries\n",
    "queries = {\n",
    "    \"total_earthquakes\": \"\"\"\n",
    "        SELECT region, EXTRACT(MONTH FROM time) AS month, COUNT(*) AS total_earthquakes\n",
    "        FROM Earthquakes\n",
    "        GROUP BY region, month;\n",
    "    \"\"\",\n",
    "    \"avg_magnitude\": \"\"\"\n",
    "        SELECT region, source, AVG(magnitude) AS avg_magnitude\n",
    "        FROM Earthquakes\n",
    "        GROUP BY region, source;\n",
    "    \"\"\",\n",
    "    \"top_earthquakes\": \"\"\"\n",
    "        SELECT *\n",
    "        FROM Earthquakes\n",
    "        ORDER BY magnitude DESC, time DESC\n",
    "        LIMIT 10;\n",
    "    \"\"\",\n",
    "    \"depth_range\": \"\"\"\n",
    "        SELECT region, MAX(depth) AS max_depth, MIN(depth) AS min_depth\n",
    "        FROM Earthquakes\n",
    "        GROUP BY region;\n",
    "    \"\"\",\n",
    "    \"delete_invalid\": \"\"\"\n",
    "        DELETE FROM Earthquakes\n",
    "        WHERE magnitude < 0\n",
    "           OR magnitude > 10\n",
    "           OR depth < 0;\n",
    "    \"\"\",\n",
    "    \"update_null_magnitude\": \"\"\"\n",
    "        UPDATE Earthquakes\n",
    "        SET magnitude = 0\n",
    "        WHERE magnitude IS NULL;\n",
    "    \"\"\",\n",
    "    \"update_null_depth\": \"\"\"\n",
    "        UPDATE Earthquakes\n",
    "        SET depth = 0\n",
    "        WHERE depth IS NULL;\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "for q in queries.values():\n",
    "    connection.execute(text(q))\n",
    "\n",
    "result = connection.execute(\n",
    "    text(\"SELECT id, time, coordination, depth, magnitude, region, source FROM Earthquakes LIMIT 5;\")\n",
    ").fetchall()\n",
    "for row in result:\n",
    "    print(row)\n",
    "output_path = \"Earthquakes_export.csv\"\n",
    "df_export = pd.read_sql(\"SELECT * FROM Earthquakes\", con=engine)\n",
    "df_export.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>coordination</th>\n",
       "      <th>depth</th>\n",
       "      <th>magnitude</th>\n",
       "      <th>region</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-09-15</td>\n",
       "      <td>[38.322, 142.369]</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>Honshu</td>\n",
       "      <td>Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-09-16</td>\n",
       "      <td>[36.2048, 138.2529]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.866667</td>\n",
       "      <td>Nagano</td>\n",
       "      <td>Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-09-18</td>\n",
       "      <td>[33.5904, 130.4017]</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.866667</td>\n",
       "      <td>Fukuoka</td>\n",
       "      <td>Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-09-19</td>\n",
       "      <td>[35.6895, 139.6917]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-09-20</td>\n",
       "      <td>[37.765, 140.467]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>Fukushima</td>\n",
       "      <td>Dataset</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         time         coordination  depth  magnitude     region   source\n",
       "0  2025-09-15    [38.322, 142.369]   35.0   5.100000     Honshu  Dataset\n",
       "1  2025-09-16  [36.2048, 138.2529]    0.0   4.866667     Nagano  Dataset\n",
       "2  2025-09-18  [33.5904, 130.4017]   12.0   4.866667    Fukuoka  Dataset\n",
       "3  2025-09-19  [35.6895, 139.6917]    0.0   5.500000      Tokyo  Dataset\n",
       "4  2025-09-20    [37.765, 140.467]    0.0   4.600000  Fukushima  Dataset"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m engine = \u001b[43mcreate_engine\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mmysql+pymysql://root:nimaaslrousta717@localhost:3306/earthquakes_db\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m connection = engine.connect()\n\u001b[32m      3\u001b[39m metadata = MetaData()\n",
      "\u001b[31mNameError\u001b[39m: name 'create_engine' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
