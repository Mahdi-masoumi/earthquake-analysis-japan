{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows inserted: 213\n",
      "(1, datetime.date(2025, 9, 15), '[38.322, 142.369]', 35.0, 5.1, 'Honshu', 'Dataset')\n",
      "(2, datetime.date(2025, 9, 16), '[36.2048, 138.2529]', 0.0, 4.86667, 'Nagano', 'Dataset')\n",
      "(3, datetime.date(2025, 9, 18), '[33.5904, 130.4017]', 12.0, 4.86667, 'Fukuoka', 'Dataset')\n",
      "(4, datetime.date(2025, 9, 19), '[35.6895, 139.6917]', 0.0, 5.5, 'Tokyo', 'Dataset')\n",
      "(5, datetime.date(2025, 9, 20), '[37.765, 140.467]', 0.0, 4.6, 'Fukushima', 'Dataset')\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String, Float, Date, text\n",
    "import pandas as pd\n",
    "#nima part\n",
    "files = [\n",
    "    (\"/Users/Vengeance/Documents/GitHub/earthquake-analysis-japan/JAPAN_DATASET_cleaned.csv\", \"Dataset\"),\n",
    "    (\"/Users/Vengeance/Documents/GitHub/earthquake-analysis-japan/JAPAN_EMSC_cleaned.csv\", \"EMSC\"),\n",
    "    (\"/Users/Vengeance/Documents/GitHub/earthquake-analysis-japan/JAPAN_GEOFON_cleaned.csv\", \"GEOFON\"),\n",
    "    (\"/Users/Vengeance/Documents/GitHub/earthquake-analysis-japan/JAPAN_USGS_cleaned.csv\", \"USGS\")\n",
    "]\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for file_path, source_name in files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    if 'place' in df.columns and 'region' in df.columns:\n",
    "        df = df.drop(columns=['place'])\n",
    "    if 'latitude' in df.columns and 'longitude' in df.columns:\n",
    "        df['coordination'] = df.apply(lambda x: f\"[{x.latitude}, {x.longitude}]\", axis=1)\n",
    "    rename_map = {}\n",
    "    if 'mag' in df.columns:\n",
    "        rename_map['mag'] = 'magnitude'\n",
    "    if 'place' in df.columns and 'region' not in df.columns:\n",
    "        rename_map['place'] = 'region'\n",
    "    df = df.rename(columns=rename_map)\n",
    "    df['source'] = source_name\n",
    "    columns_needed = ['time', 'coordination', 'depth', 'magnitude', 'region', 'source']\n",
    "    df = df[[c for c in columns_needed if c in df.columns]]\n",
    "    if 'time' in df.columns:\n",
    "        df['time'] = pd.to_datetime(df['time'], errors='coerce').dt.date\n",
    "    if 'depth' in df.columns:\n",
    "        df['depth'] = pd.to_numeric(df['depth'], errors='coerce')\n",
    "    if 'magnitude' in df.columns:\n",
    "        df['magnitude'] = pd.to_numeric(df['magnitude'], errors='coerce')\n",
    "    dfs.append(df)\n",
    "\n",
    "df_all = pd.concat(dfs, ignore_index=True)\n",
    "df_all = df_all.dropna(subset=['time', 'magnitude', 'region'])\n",
    "df_all = df_all.drop_duplicates()\n",
    "\n",
    "engine = create_engine(\"mysql+pymysql://root:nimaaslrousta717@localhost:3306/earthquakes_db\")\n",
    "connection = engine.connect()\n",
    "metadata = MetaData()\n",
    "\n",
    "earthquakes = Table(\n",
    "    'Earthquakes',\n",
    "    metadata,\n",
    "    Column('id', Integer, primary_key=True),\n",
    "    Column('time', Date),\n",
    "    Column('coordination', String(50)),\n",
    "    Column('depth', Float),\n",
    "    Column('magnitude', Float),\n",
    "    Column('region', String(100)),\n",
    "    Column('source', String(50))\n",
    ")\n",
    "\n",
    "connection.execute(text(\"DROP TABLE IF EXISTS Earthquakes;\"))\n",
    "metadata.create_all(engine)\n",
    "\n",
    "df_all.to_sql(\n",
    "    name='Earthquakes',\n",
    "    con=engine,\n",
    "    if_exists='append',\n",
    "    index=False,\n",
    "    chunksize=1000\n",
    ")\n",
    "\n",
    "count = connection.execute(text(\"SELECT COUNT(*) FROM Earthquakes;\")).scalar()\n",
    "print(f\"Number of rows inserted: {count}\")\n",
    "#sepehr queries\n",
    "queries = {\n",
    "    \"total_earthquakes\": \"\"\"\n",
    "        SELECT region, EXTRACT(MONTH FROM time) AS month, COUNT(*) AS total_earthquakes\n",
    "        FROM Earthquakes\n",
    "        GROUP BY region, month;\n",
    "    \"\"\",\n",
    "    \"avg_magnitude\": \"\"\"\n",
    "        SELECT region, source, AVG(magnitude) AS avg_magnitude\n",
    "        FROM Earthquakes\n",
    "        GROUP BY region, source;\n",
    "    \"\"\",\n",
    "    \"top_earthquakes\": \"\"\"\n",
    "        SELECT *\n",
    "        FROM Earthquakes\n",
    "        ORDER BY magnitude DESC, time DESC\n",
    "        LIMIT 10;\n",
    "    \"\"\",\n",
    "    \"depth_range\": \"\"\"\n",
    "        SELECT region, MAX(depth) AS max_depth, MIN(depth) AS min_depth\n",
    "        FROM Earthquakes\n",
    "        GROUP BY region;\n",
    "    \"\"\",\n",
    "    \"delete_invalid\": \"\"\"\n",
    "        DELETE FROM Earthquakes\n",
    "        WHERE magnitude < 0\n",
    "           OR magnitude > 10\n",
    "           OR depth < 0;\n",
    "    \"\"\",\n",
    "    \"update_null_magnitude\": \"\"\"\n",
    "        UPDATE Earthquakes\n",
    "        SET magnitude = 0\n",
    "        WHERE magnitude IS NULL;\n",
    "    \"\"\",\n",
    "    \"update_null_depth\": \"\"\"\n",
    "        UPDATE Earthquakes\n",
    "        SET depth = 0\n",
    "        WHERE depth IS NULL;\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "for q in queries.values():\n",
    "    connection.execute(text(q))\n",
    "\n",
    "result = connection.execute(\n",
    "    text(\"SELECT id, time, coordination, depth, magnitude, region, source FROM Earthquakes LIMIT 5;\")\n",
    ").fetchall()\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
